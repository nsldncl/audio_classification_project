{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "audio_dataset_creation_file.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchlibrosa loguru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_rx_O4c5aqm",
        "outputId": "b75debe5-eb65-4f2b-a49a-8430638b15ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchlibrosa\n",
            "  Downloading torchlibrosa-0.0.9-py3-none-any.whl (11 kB)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.5.3-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchlibrosa) (1.19.5)\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from torchlibrosa) (0.8.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (0.10.3.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (2.1.9)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (0.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (21.3)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (4.4.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (1.1.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (0.51.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.6.0->torchlibrosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.6.0->torchlibrosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa>=0.6.0->torchlibrosa) (3.0.6)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.6.0->torchlibrosa) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.6.0->torchlibrosa) (2.23.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa>=0.6.0->torchlibrosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.6.0->torchlibrosa) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa>=0.6.0->torchlibrosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.6.0->torchlibrosa) (2.21)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa>=0.6.0->torchlibrosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa>=0.6.0->torchlibrosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa>=0.6.0->torchlibrosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa>=0.6.0->torchlibrosa) (2021.10.8)\n",
            "Installing collected packages: torchlibrosa, loguru\n",
            "Successfully installed loguru-0.5.3 torchlibrosa-0.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "zeEDTkO79xpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euhvslymHpVx",
        "outputId": "b6fb5ac1-c1db-4562-b6bf-5cc68fc0b330"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls6qZeL6WuI9"
      },
      "source": [
        "import torch.nn as nn\n",
        "import cv2\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
        "from torchlibrosa.augmentation import SpecAugmentation\n",
        "import pandas as pd\n",
        "import torch\n",
        "import librosa, librosa.display\n",
        "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
        "from torchlibrosa.augmentation import SpecAugmentation\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import csv\n",
        "\n",
        "\n",
        "\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "from loguru import logger\n",
        "from pathlib import Path\n",
        "from itertools import chain\n",
        "from re import sub"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://zenodo.org/record/4783391/files/clotho_captions_evaluation.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-RiBKJ3BRLJ",
        "outputId": "b97a111f-c16b-4cab-bdfa-f2457841976d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-25 05:44:25--  https://zenodo.org/record/4783391/files/clotho_captions_evaluation.csv\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 361995 (354K) [text/plain]\n",
            "Saving to: ‘clotho_captions_evaluation.csv’\n",
            "\n",
            "clotho_captions_eva 100%[===================>] 353.51K   824KB/s    in 0.4s    \n",
            "\n",
            "2021-12-25 05:44:27 (824 KB/s) - ‘clotho_captions_evaluation.csv’ saved [361995/361995]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basepath = '/content/drive/MyDrive/Upwork/eval_100'\n",
        "df = pd.read_csv('/content/clotho_captions_evaluation.csv')\n",
        "file_name = []\n",
        "c1 = []\n",
        "c2 = []\n",
        "c3 = []\n",
        "c4 = []\n",
        "c5 = []\n",
        "for filename in os.listdir(basepath):\n",
        "  file_name.append(filename)\n",
        "  c1.append(df[df[\"file_name\"] == filename]['caption_1'].iloc[0])\n",
        "  c2.append(df[df[\"file_name\"] == filename]['caption_2'].iloc[0])\n",
        "  c3.append(df[df[\"file_name\"] == filename]['caption_3'].iloc[0])\n",
        "  c4.append(df[df[\"file_name\"] == filename]['caption_4'].iloc[0])\n",
        "  c5.append(df[df[\"file_name\"] == filename]['caption_5'].iloc[0])\n",
        "\n",
        "data = pd.DataFrame({'file_name':file_name, 'caption_1':c1, 'caption_2':c2, 'caption_3':c3, 'caption_4':c4, 'caption_5':c5})\n",
        "data.to_csv('/content/new_audio_data.csv')"
      ],
      "metadata": {
        "id": "ea0fSTaMnxid"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_csv_file(csv_obj, file_name):\n",
        "    with open(file_name, 'w') as f:\n",
        "        writer = csv.DictWriter(f, csv_obj[0].keys())\n",
        "        writer.writeheader()\n",
        "        writer.writerows(csv_obj)\n",
        "    print(f'Write to {file_name} successfully.')\n",
        "\n",
        "def load_csv_file(file_name):\n",
        "    with open(file_name, 'r') as f:\n",
        "        csv_reader = csv.DictReader(f)\n",
        "        csv_obj = [csv_line for csv_line in csv_reader]\n",
        "    return csv_obj\n",
        "\n",
        "def load_picke_file(file_name):\n",
        "    with open(file_name, 'rb') as f:\n",
        "        pickle_obj = pickle.load(f)\n",
        "    return pickle_obj\n",
        "\n",
        "def write_pickle_file(obj, file_name):\n",
        "    with open(file_name, 'wb') as f:\n",
        "        pickle.dump(obj, f)\n",
        "    print(f'Write to {file_name} successfully.')"
      ],
      "metadata": {
        "id": "UQavkVLvIT2O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset():\n",
        "    inner_logger = logger\n",
        "    inner_logger.info('Loading csv files and process each caption.')\n",
        "\n",
        "    dev_csv = load_csv_file('/content/new_audio_data.csv')\n",
        "    # val_csv = load_csv_file('/content/clotho_captions_validation.csv')\n",
        "    # eval_csv = load_csv_file('/content/clotho_captions_evaluation.csv')\n",
        "    caption_fields = ['caption_{}'.format(i) for i in range(1, 6)]\n",
        "    for csv_item in chain(dev_csv):\n",
        "        ''' Process each caption'''\n",
        "        captions = [_sentence_process(csv_item[caption_field], add_specials=True) for caption_field in caption_fields]\n",
        "        [csv_item.update({caption_field: caption})\n",
        "         for caption_field, caption in zip(caption_fields, captions)]\n",
        "    inner_logger.info('Done!')\n",
        "    words_list = load_picke_file('/content/drive/MyDrive/Upwork/new_words_list.p')\n",
        "\n",
        "    for split_data in [(dev_csv, 'development')]:\n",
        "        split_csv = split_data[0]\n",
        "        split_name = split_data[1]\n",
        "        split_dir = Path('data/data_splits', split_name)\n",
        "        split_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        audio_dir = Path('/content/drive/MyDrive/Upwork/eval_100')\n",
        "        inner_logger.info(f'Creating the {split_name} split.')\n",
        "        _create_split_data(split_csv, split_dir, audio_dir, words_list)\n",
        "        inner_logger.info('Done')\n",
        "        audio_number = len(os.listdir(str(audio_dir)))\n",
        "        data_number = len(os.listdir(str(split_dir)))\n",
        "\n",
        "        inner_logger.info('{} audio files in {}.'.format(audio_number, split_name))\n",
        "        inner_logger.info('{} data files in {}'.format(data_number, split_name))\n",
        "        inner_logger.info('{} data files per audio.'.format(data_number / audio_number))\n",
        "\n",
        "    inner_logger.info('Dataset created')\n",
        "\n",
        "\n",
        "def _create_vocabulary(captions):\n",
        "    words_list = []\n",
        "    vocabulary = []\n",
        "    for caption in captions:\n",
        "        caption_words = caption.strip().split()\n",
        "        vocabulary.extend(caption_words)\n",
        "    words_list = list(set(vocabulary))\n",
        "    words_list.sort(key=vocabulary.index)\n",
        "    words_freq = [vocabulary.count(word) for word in words_list]\n",
        "\n",
        "    return words_list, words_freq\n",
        "\n",
        "\n",
        "def _sentence_process(sentence, add_specials=False):\n",
        "    sentence = sentence.lower()\n",
        "    if add_specials:\n",
        "        sentence = '<sos> {} <eos>'.format(sentence)\n",
        "    # remove any forgotten space before punctuation and double space\n",
        "    sentence = sub(r'\\s([,.!?;:\"](?:\\s|$))', r'\\1', sentence).replace('  ', ' ')\n",
        "    # remove punctuations\n",
        "    sentence = sub('[,.!?;:\\\"]', ' ', sentence).replace('  ', ' ')\n",
        "    return sentence\n",
        "\n",
        "\n",
        "def _create_split_data(split_csv, split_dir, audio_dir, words_list):\n",
        "    sr = 22050#args.sr\n",
        "    n_fft = 1024#args.n_fft\n",
        "    hop_length = 512#args.hop_length\n",
        "    n_mels = 64#args.n_mels\n",
        "    window = 'hann'#args.window\n",
        "\n",
        "    caption_fields = ['caption_{}'.format(i) for i in range(1, 6)]\n",
        "    file_name_template = 'clotho_file_{audio_file_name}_{caption_index}.npy'\n",
        "    for csv_entry in tqdm(split_csv, total=len(split_csv)):\n",
        "        audio_file_name = csv_entry['file_name']\n",
        "        audio, _ = librosa.load(audio_dir.joinpath(audio_file_name), sr=sr)\n",
        "        feature = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft,\n",
        "                                                 hop_length=hop_length,\n",
        "                                                 n_mels=n_mels, window=window)\n",
        "        feature = librosa.power_to_db(feature).T\n",
        "        for caption_index, caption_field in enumerate(caption_fields):\n",
        "            caption = csv_entry[caption_field]\n",
        "            caption_words = caption.strip().split()\n",
        "            words_indexs = [words_list.index(word) for word in caption_words]\n",
        "            np_rec_array = np.rec.array(np.array(\n",
        "                (audio_file_name, audio, feature, caption, caption_index, np.array(words_indexs)),\n",
        "                dtype=[\n",
        "                    ('file_name', 'U{}'.format(len(audio_file_name))),\n",
        "                    ('audio_data', np.dtype(object)),\n",
        "                    ('feature', np.dtype(object)),\n",
        "                    ('caption', 'U{}'.format(len(caption))),\n",
        "                    ('caption_index', 'i4'),\n",
        "                    ('words_indexs', np.dtype(object))\n",
        "                ]\n",
        "            ))\n",
        "            # save the numpy object\n",
        "            file_name = str(split_dir.joinpath(file_name_template.format(\n",
        "                                audio_file_name=  audio_file_name, caption_index=caption_index)))\n",
        "            np.save(file_name, np_rec_array)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    create_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "F3OZLmXeIHNP",
        "outputId": "e15e6f61-aa74-4b3e-ceab-f99c2b3c0087"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-25 05:45:38.251 | INFO     | __main__:create_dataset:3 - Loading csv files and process each caption.\n",
            "2021-12-25 05:45:38.260 | INFO     | __main__:create_dataset:14 - Done!\n",
            "2021-12-25 05:45:38.533 | INFO     | __main__:create_dataset:24 - Creating the development split.\n",
            "  9%|▉         | 9/100 [00:14<02:29,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-146470e19b67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-146470e19b67>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0maudio_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Upwork/eval_100'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0minner_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Creating the {split_name} split.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0m_create_split_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0minner_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0maudio_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-146470e19b67>\u001b[0m in \u001b[0;36m_create_split_data\u001b[0;34m(split_csv, split_dir, audio_dir, words_list)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcsv_entry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0maudio_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_entry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         feature = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft,\n\u001b[1;32m     74\u001b[0m                                                  \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/resampy/core.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mresample_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}